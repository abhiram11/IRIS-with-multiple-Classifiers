{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhir\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "c:\\users\\abhir\\appdata\\local\\programs\\python\\python35\\lib\\importlib\\_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "print(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(data.data)\n",
    "labels = pd.DataFrame(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 3 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8f1590e19523>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\abhir\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   4387\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4388\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4389\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4390\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4391\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhir\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\abhir\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m   3321\u001b[0m             raise ValueError(\n\u001b[0;32m   3322\u001b[0m                 \u001b[1;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3323\u001b[1;33m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[0;32m   3324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3325\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 3 elements"
     ]
    }
   ],
   "source": [
    "#features.columns = data.feature_names\n",
    "#labels.columns = data.target_names\n",
    "#Column names already there\n",
    "# 0 is for setosa,1 for versicolor,2 for virginica\n",
    "#above comment represents one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiers loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#variation in parameters will be done later/other projects\n",
    "\n",
    "classifiers = { \"K-Nearest Neighbors\" : KNeighborsClassifier(n_neighbors=3),\n",
    "               \"Logistic Regression\" : LogisticRegression(random_state=42),\n",
    "               \"Stochastic Gradient Descent\" :SGDClassifier(random_state=42),\n",
    "                \"Linear SVC\" : LinearSVC(random_state=42),\n",
    "               \"Decision Tree Classifier\" : DecisionTreeClassifier(random_state=42),\n",
    "}\n",
    "print(\"Classifiers loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, y_train, y_test = train_test_split(features, labels,test_size=0.3, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models succesfully trained!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhir\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n",
      "c:\\users\\abhir\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "c:\\users\\abhir\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "values = []\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
    "    if clf_name == \"K-Nearest Neighbors\":\n",
    "        names.append(\"KNN\")\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        score = clf.score(x_test,y_test)\n",
    "        values.append(score*100)\n",
    "    elif clf_name == \"Logistic Regression\":\n",
    "        names.append(\"Log_Reg\")\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        score = clf.score(x_test,y_test)\n",
    "        values.append(score*100)\n",
    "    elif clf_name == \"Stochastic Gradient Descent\":\n",
    "        names.append(\"SGD\")\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        score = clf.score(x_test,y_test)\n",
    "        values.append(score*100)\n",
    "    elif clf_name == \"Linear SVC\":\n",
    "        names.append(\"SVC\")\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        score = clf.score(x_test,y_test)\n",
    "        values.append(score*100)\n",
    "    else:\n",
    "        names.append(\"Decision tree\")\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        score = clf.score(x_test, y_test)\n",
    "        values.append(score*100)\n",
    "print(\"Models succesfully trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(names, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier : KNN , Accuracy : 95.55555555555556\n",
      "Classifier : SGD , Accuracy : 66.66666666666666\n",
      "Classifier : Decision tree , Accuracy : 91.11111111111111\n",
      "Classifier : SVC , Accuracy : 91.11111111111111\n",
      "Classifier : Log_Reg , Accuracy : 91.11111111111111\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(names)):\n",
    "    print('Classifier : {} , Accuracy : {}'.format(names[i],values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
